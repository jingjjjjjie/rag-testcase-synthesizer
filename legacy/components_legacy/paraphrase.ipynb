{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ba7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from tools.string_utils import read_text_file\n",
    "from tools.json_utils import load_json, save_json\n",
    "from tools.api import call_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed866e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 items from ../data/final_answer_generated_rephrased.json\n"
     ]
    }
   ],
   "source": [
    "PARAPHRASE_INPUT_PATH  = '../data/final_answer_generated_rephrased.json'\n",
    "PARAPHRASE_OUTPUT_PATH = '../data/final_answer_generated_rephrased_paraphrased.json'\n",
    "PARAPHRASE_PROMPT_PATH = '../prompts/paraphrase.txt'\n",
    "\n",
    "SENTENCE_ORDER_CHANGER_NUM_WORKERS = 4\n",
    "SENTENCE_ORDER_CHANGER_MAX_GEN_TIMES = 100\n",
    "TEMPERATURE = float(os.getenv(\"TEMPERATURE\", 0.6))\n",
    "\n",
    "save_interval = 10\n",
    "\n",
    "inputs = load_json(PARAPHRASE_INPUT_PATH)\n",
    "sentence_changer_prompt = read_text_file(PARAPHRASE_PROMPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "458b26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_numbers_and_ranges(numbers_and_ranges):\n",
    "    expanded_numbers = []\n",
    "    for item in numbers_and_ranges:\n",
    "        if '-' in item:  # It's a range like 'xx1-xx2'\n",
    "            start, end = map(int, item.split('-'))\n",
    "            if start > end:\n",
    "                start, end = end, start\n",
    "            expanded_numbers.extend(range(start, end + 1))\n",
    "        else:  # It's a single number\n",
    "            expanded_numbers.append(int(item))\n",
    "    expanded_numbers = list(sorted(list(set(expanded_numbers))))\n",
    "    return expanded_numbers\n",
    "\n",
    "def parse_transformations(text):\n",
    "    \"\"\"\n",
    "    Parses the transformed questions and their metadata from the provided text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing the transformed questions.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of dictionaries, each containing the question number,\n",
    "                      transformed question, and the same-meaning-with-origin value.\n",
    "    \"\"\"\n",
    "    # Regex pattern to match each transformation block\n",
    "    pattern = re.compile(r'''\n",
    "        \\s*<question-\\d+>                               # Match the question number and opening tag\n",
    "        \\s*<transformed-question>(.*?)</transformed-question> # Capture the transformed question\n",
    "        \\s*<same-meaning-with-origin>(True|False)</same-meaning-with-origin> # Capture the boolean value\n",
    "        \\s*</question-\\d+>                                   # Match the closing tag\n",
    "        ''', re.DOTALL | re.VERBOSE)\n",
    "\n",
    "    transformations = []\n",
    "\n",
    "    # Find all matches in the text\n",
    "    for match in pattern.finditer(text):\n",
    "        transformed_question = match.group(1).strip()\n",
    "        same_meaning = match.group(2).strip() == 'True'\n",
    "        \n",
    "        # Extract the question number from the matched string\n",
    "        question_tag = re.search(r'<question-(\\d+)>', match.group(0))\n",
    "        question_number = int(question_tag.group(1)) if question_tag else None\n",
    "\n",
    "        transformations.append({\n",
    "            'question_number': question_number,\n",
    "            'transformed_question': transformed_question,\n",
    "            'same_meaning_with_origin': same_meaning\n",
    "        })\n",
    "\n",
    "    return transformations\n",
    "\n",
    "def run():\n",
    "    all_num, success_num = 0, 0\n",
    "    tasks = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=SENTENCE_ORDER_CHANGER_NUM_WORKERS) as executor:\n",
    "        for i, cur_input in enumerate(inputs[:SENTENCE_ORDER_CHANGER_MAX_GEN_TIMES]):\n",
    "\n",
    "            questions = cur_input['proposed-questions']\n",
    "            objective_facts = cur_input['objective-facts']\n",
    "\n",
    "            for proposed_question_type, proposed_question_dict in questions.items():\n",
    "\n",
    "                context = \"Given clues:\\n\"\n",
    "                for idx, clue in enumerate(objective_facts, start=1):\n",
    "                    context += f\"{idx}. {clue}\\n\"\n",
    "                context += \"\\n\"\n",
    "                context += f\"Questions and Answers: \\n\"\n",
    "                if 'rephrased-questions' in proposed_question_dict:\n",
    "                    rephrased_questions = proposed_question_dict['rephrased-questions']\n",
    "                    already_processed = False\n",
    "                    for j, cur_rephrased_question in enumerate(rephrased_questions, start=1):\n",
    "                        if 'reordered-question' in cur_rephrased_question:\n",
    "                            already_processed = True\n",
    "                            break\n",
    "                        context += f\"<question-{j}>{cur_rephrased_question['result']}</question-{j}>\\n\"\n",
    "                        context += f\"<answer-{j}>{cur_rephrased_question['answer']}</answer-{j}>\\n\"\n",
    "                    if not already_processed:\n",
    "                        context += \"\\n\"\n",
    "                        cur_sentence_changer_prompt = sentence_changer_prompt.replace('[[CONTEXT]]', context)\n",
    "                        future = executor.submit(call_api, cur_sentence_changer_prompt, TEMPERATURE)\n",
    "                        tasks.append((future, rephrased_questions))\n",
    "\n",
    "                # context = \"Given clues:\\n\"\n",
    "                # for idx, clue in enumerate(objective_facts, start=1):\n",
    "                #     context += f\"{idx}. {clue}\\n\"\n",
    "                # context += \"\\n\"\n",
    "                # context += f\"Questions and Answers: \\n\"\n",
    "                # if 'rephrased-questions-part' in proposed_question_dict:\n",
    "                #     rephrased_questions_part = proposed_question_dict['rephrased-questions-part']\n",
    "                #     already_processed = False\n",
    "                #     for j, cur_rephrased_question_part in enumerate(rephrased_questions_part, start=1):\n",
    "                #         if 'reordered-question' in cur_rephrased_question_part:\n",
    "                #             already_processed = True\n",
    "                #             break\n",
    "                #         context += f\"<question-{j}>{cur_rephrased_question_part['result']}</question-{j}>\\n\"\n",
    "                #         context += f\"<answer-{j}>{cur_rephrased_question_part['answer']}</answer-{j}>\\n\"\n",
    "                #     if not already_processed:\n",
    "                #         context += \"\\n\"\n",
    "                #         cur_sentence_changer_prompt = sentence_changer_prompt.replace('[[CONTEXT]]', context)\n",
    "                #         future = executor.submit(call_api, cur_sentence_changer_prompt, TEMPERATURE)\n",
    "                #         tasks.append((future, rephrased_questions_part))\n",
    "\n",
    "                # context = \"Given clues:\\n\"\n",
    "                # for idx, clue in enumerate(objective_facts, start=1):\n",
    "                #     context += f\"{idx}. {clue}\\n\"\n",
    "                # context += \"\\n\"\n",
    "                # context += f\"Questions and Answers: \\n\"\n",
    "                # if 'rephrased-questions-hybrid' in proposed_question_dict:\n",
    "                #     rephrased_questions_hybrid = proposed_question_dict['rephrased-questions-hybrid']\n",
    "                #     already_processed = False\n",
    "                #     for j, cur_rephrased_question_hybrid in enumerate(rephrased_questions_hybrid, start=1):\n",
    "                #         if 'reordered-question' in cur_rephrased_question_hybrid:\n",
    "                #             already_processed = True\n",
    "                #             break\n",
    "                #         context += f\"<question-{j}>{cur_rephrased_question_hybrid['result']}</question-{j}>\\n\"\n",
    "                #         context += f\"<answer-{j}>{cur_rephrased_question_hybrid['answer']}</answer-{j}>\\n\"\n",
    "                #     if not already_processed:\n",
    "                #         context += \"\\n\"\n",
    "                #         cur_sentence_changer_prompt = sentence_changer_prompt.replace('[[CONTEXT]]', context)\n",
    "                #         future = executor.submit(self.openai_model.generate, self.CLIENT, cur_sentence_changer_prompt, TEMPERATURE)\n",
    "                #         tasks.append((future, rephrased_questions_hybrid))\n",
    "\n",
    "        all_num = len(tasks)\n",
    "        for future_info in tqdm(as_completed([t[0] for t in tasks]), total=len(tasks), desc=\"Generating\", dynamic_ncols=True):\n",
    "            future = future_info\n",
    "            idx = [t[0] for t in tasks].index(future)\n",
    "            if idx == -1:\n",
    "                raise ValueError(\"Invalid index.\")\n",
    "            rephrased_questions = tasks[idx][1]\n",
    "\n",
    "            sentence_changer_response = future.result(timeout=10*60)\n",
    "            reordered_questions = parse_transformations(sentence_changer_response)\n",
    "            reordered_question_index2dict = {\n",
    "                reordered_question['question_number']: reordered_question\n",
    "                for reordered_question in reordered_questions\n",
    "            }\n",
    "\n",
    "            for j, cur_rephrased_question_part in enumerate(rephrased_questions, start=1):\n",
    "                if j not in reordered_question_index2dict:\n",
    "                    continue\n",
    "                cur_rephrased_question_part['paraphrased-question'] = reordered_question_index2dict[j]['transformed_question']\n",
    "                cur_rephrased_question_part['paraphrased-same-meaning-with-origin-llmCheck'] = reordered_question_index2dict[j]['same_meaning_with_origin']\n",
    "            \n",
    "            success_num += 1\n",
    "            if success_num % save_interval == 0:\n",
    "                print(f'Saving {success_num}/{all_num} outputs to {PARAPHRASE_OUTPUT_PATH}.')\n",
    "                save_json(inputs,PARAPHRASE_OUTPUT_PATH)\n",
    "\n",
    "    if success_num or not os.path.exists(PARAPHRASE_OUTPUT_PATH):\n",
    "        print(f'Saving {success_num}/{all_num} outputs to {PARAPHRASE_OUTPUT_PATH}.')\n",
    "        save_json(inputs,PARAPHRASE_OUTPUT_PATH)\n",
    "\n",
    "    return success_num, all_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b702aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  33%|███▎      | 10/30 [00:17<00:29,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 10/30 outputs to ../data/final_answer_generated_rephrased_paraphrased.json.\n",
      "Saved 10 items to ../data/final_answer_generated_rephrased_paraphrased.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  67%|██████▋   | 20/30 [00:32<00:13,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 20/30 outputs to ../data/final_answer_generated_rephrased_paraphrased.json.\n",
      "Saved 10 items to ../data/final_answer_generated_rephrased_paraphrased.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 30/30 [00:48<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 30/30 outputs to ../data/final_answer_generated_rephrased_paraphrased.json.\n",
      "Saved 10 items to ../data/final_answer_generated_rephrased_paraphrased.json\n",
      "Saving 30/30 outputs to ../data/final_answer_generated_rephrased_paraphrased.json.\n",
      "Saved 10 items to ../data/final_answer_generated_rephrased_paraphrased.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragsynth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
