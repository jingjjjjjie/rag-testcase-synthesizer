{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d947137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict,List\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from tools.string_utils import read_text_file\n",
    "from tools.json_utils import load_json, save_json\n",
    "from tools.api import call_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c801801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answers(prompt):\n",
    "    # Define regular expressions to capture the short and long answers\n",
    "    short_answer_pattern = r\"<answer-short>\\s*<reason>(.*?)</reason>\\s*<answer>(.*?)</answer>\\s*</answer-short>\"\n",
    "    long_answer_pattern = r\"<answer-long>\\s*<reason>(.*?)</reason>\\s*<answer>(.*?)</answer>\\s*</answer-long>\"\n",
    "\n",
    "    # Search for the patterns in the prompt\n",
    "    short_answer_match = re.search(short_answer_pattern, prompt, re.DOTALL)\n",
    "    long_answer_match = re.search(long_answer_pattern, prompt, re.DOTALL)\n",
    "\n",
    "    # Extract the reason and answer for short and long answers\n",
    "    if short_answer_match:\n",
    "        short_reason = short_answer_match.group(1).strip()\n",
    "        short_answer = short_answer_match.group(2).strip()\n",
    "    else:\n",
    "        short_reason = None\n",
    "        short_answer = None\n",
    "\n",
    "    if long_answer_match:\n",
    "        long_reason = long_answer_match.group(1).strip()\n",
    "        long_answer = long_answer_match.group(2).strip()\n",
    "    else:\n",
    "        long_reason = None\n",
    "        long_answer = None\n",
    "\n",
    "    return {\n",
    "        \"short-answer\": {\n",
    "            \"reason\": short_reason,\n",
    "            \"answer\": short_answer\n",
    "        },\n",
    "        \"long-answer\": {\n",
    "            \"reason\": long_reason,\n",
    "            \"answer\": long_answer\n",
    "        }\n",
    "    }\n",
    "\n",
    "def process_input_content(cur_input, cur_prompt):\n",
    "        try:\n",
    "            cur_response = call_api(cur_prompt, temperature=0.6)\n",
    "            answers = extract_answers(cur_response)\n",
    "            cur_input['positive'] = answers['short-answer']['answer']\n",
    "            cur_input['corrected-answer'] = answers\n",
    "            return cur_input\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"An error occurred while processing input\")\n",
    "            return None, None\n",
    "        \n",
    "def expand_numbers_and_ranges(numbers_and_ranges):\n",
    "    expanded_numbers = []\n",
    "    for item in numbers_and_ranges:\n",
    "        if '-' in item:  # It's a range like 'xx1-xx2'\n",
    "            start, end = map(int, item.split('-'))\n",
    "            if start > end:\n",
    "                end, start = start, end\n",
    "            expanded_numbers.extend(range(start, end + 1))\n",
    "        else:  # It's a single number\n",
    "            expanded_numbers.append(int(item))\n",
    "    expanded_numbers = list(sorted(list(set(expanded_numbers))))\n",
    "    return expanded_numbers\n",
    "\n",
    "def list_to_docided_string(string_dict):\n",
    "    \"\"\"\n",
    "    Convert a list of strings into a docided string.\n",
    "\n",
    "    :param string_list: list of str, the list of strings to be converted\n",
    "    :return: str, the resulting numbered string\n",
    "    \"\"\"\n",
    "    numbered_string = \"\"\n",
    "    for index, (doc_id, doc_content) in enumerate(string_dict.items()):\n",
    "        numbered_string += f\"\"\"{index}. <doc>\n",
    "    <doc-name>{doc_id}</doc-name>\n",
    "    <detailed-desc>{doc_content}</detailed-desc>\n",
    "</doc>\n",
    "\"\"\"\n",
    "    return numbered_string.strip()\n",
    "\n",
    "def extract_and_remove_think_tags(text):\n",
    "    # Find all content inside <think> tags\n",
    "    think_contents = re.findall(r'<think>(.*?)</think>', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove all <think> tags and their contents from the text\n",
    "    cleaned_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    return think_contents, cleaned_text\n",
    "\n",
    "def replace_clue_with_doc_and_sen(all_clueid2docid2senidlist: Dict[int, Dict[int, List[int]]], positive_answer: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces [Clue xx] or [Clue xx-yy] citations in the positive_answer with formatted [Doc xx, Sen xx] citations.\n",
    "    \n",
    "    Parameters:\n",
    "    - all_clueid2docid2senidlist: Dict mapping clue IDs to another dict mapping doc IDs to lists of sentence IDs.\n",
    "      Example:\n",
    "      {\n",
    "          1: {1: [1, 2, 3]},\n",
    "          2: {1: [4, 5]},\n",
    "          3: {2: [1, 2]},\n",
    "          4: {2: [3]},\n",
    "      }\n",
    "    - positive_answer: String containing [Clue xx] or [Clue xx-yy] patterns.\n",
    "    \n",
    "    Returns:\n",
    "    - new_answer: String with [Clue xx] patterns replaced by formatted citations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def expand_range(token: str) -> List[int]:\n",
    "        \"\"\"\n",
    "        Expands a token which can be a single number or a range (e.g., '2' or '2-8') into a list of integers.\n",
    "        \"\"\"\n",
    "        if '-' in token:\n",
    "            start, end = token.split('-')\n",
    "            return list(range(int(start), int(end) + 1))\n",
    "        else:\n",
    "            return [int(token)]\n",
    "    \n",
    "    def expand_range_in_list(tokens: List[str]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Processes a list of tokens, expanding ranges and collecting all clue IDs.\n",
    "        \"\"\"\n",
    "        clue_ids = []\n",
    "        for token in tokens:\n",
    "            if '-' in token:\n",
    "                clue_ids.extend(expand_range(token))\n",
    "            else:\n",
    "                if token.isdigit():\n",
    "                    clue_ids.append(int(token))\n",
    "        return clue_ids\n",
    "    \n",
    "    def expand_sen_ranges(nums: List[int]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Converts a sorted list of integers into a list with ranges for consecutive numbers.\n",
    "        Example: [1,2,3,5] -> ['1-3', '5']\n",
    "        \"\"\"\n",
    "        if not nums:\n",
    "            return []\n",
    "\n",
    "        nums = sorted(nums)\n",
    "        ranges = []\n",
    "        start = prev = nums[0]\n",
    "\n",
    "        for num in nums[1:]:\n",
    "            if num == prev + 1:\n",
    "                prev = num\n",
    "            else:\n",
    "                if prev - start >= 2:\n",
    "                    ranges.append(f\"{start}-{prev}\")\n",
    "                elif prev - start == 1:\n",
    "                    ranges.append(str(start))\n",
    "                    ranges.append(str(prev))\n",
    "                else:\n",
    "                    ranges.append(str(start))\n",
    "                start = prev = num\n",
    "\n",
    "        # Handle the last range\n",
    "        if prev - start >= 2:\n",
    "            ranges.append(f\"{start}-{prev}\")\n",
    "        elif prev - start == 1:\n",
    "            ranges.append(str(start))\n",
    "            ranges.append(str(prev))\n",
    "        else:\n",
    "            ranges.append(str(start))\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    # Regular expression to find [Clue xx], [Clue xx, yy], [Clue xx-yy], etc.\n",
    "    clue_pattern = re.compile(r'\\[Clue\\s+([^\\]]+)\\]')\n",
    "    \n",
    "    def replacement(match):\n",
    "        # print(\"match:\", match)\n",
    "        clue_ids_str = match.group(1)\n",
    "        # Split by comma and/or whitespace\n",
    "        tokens = re.split(r'[,\\s]+', clue_ids_str)\n",
    "        # Expand tokens to individual clue IDs\n",
    "        clue_ids = expand_range_in_list(tokens)\n",
    "        # print(\"clue_ids:\", clue_ids)\n",
    "        \n",
    "        # Map doc_id to set of sen_ids\n",
    "        doc_to_sens = {}\n",
    "        for cid in clue_ids:\n",
    "            if cid in all_clueid2docid2senidlist:\n",
    "                for doc_id, sen_ids in all_clueid2docid2senidlist[cid].items():\n",
    "                    if doc_id not in doc_to_sens:\n",
    "                        doc_to_sens[doc_id] = set()\n",
    "                    doc_to_sens[doc_id].update(sen_ids)\n",
    "        \n",
    "        if not doc_to_sens:\n",
    "            # No valid clues found, return the original string\n",
    "            return match.group(0)\n",
    "        \n",
    "        # Build the citation strings\n",
    "        citations = []\n",
    "        for doc_id in sorted(doc_to_sens.keys()):\n",
    "            sen_list = sorted(doc_to_sens[doc_id])\n",
    "            sen_ranges = expand_sen_ranges(sen_list)\n",
    "\n",
    "            if sen_ranges:\n",
    "                # Prepend 'Sen ' to each range\n",
    "                sen_formatted = [f\"{s}\" for s in sen_ranges]\n",
    "                sen_formatted[0] = f\"Sen {sen_formatted[0]}\"\n",
    "                # Join sentence parts with comma\n",
    "                sen_str = \", \".join(sen_formatted)\n",
    "                citations.append(f\"Doc {doc_id}, {sen_str}\")\n",
    "            else:\n",
    "                citations.append(f\"\")\n",
    "        \n",
    "        # Format multiple documents with separate brackets\n",
    "        if len(citations) == 1:\n",
    "            return f\"[{citations[0]}]\"\n",
    "        else:\n",
    "            # Each document citation in its own brackets\n",
    "            return \"\".join(f\"[{cit}]\" for cit in citations)\n",
    "    \n",
    "    # Replace all [Clue ...] patterns using the replacement function\n",
    "    new_answer = clue_pattern.sub(replacement, positive_answer)\n",
    "    \n",
    "    return new_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0f96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 items from ../data/proposed_questions.json\n",
      "Loaded 10 items from ../data/proposed_questions.json\n"
     ]
    }
   ],
   "source": [
    "FINAL_ANSWER_GENERATOR_NUM_WORKERS = 4\n",
    "FINAL_ANSWER_GENERATOR_MAX_GEN_TIMES = 100\n",
    "FINAL_ANSWER_GENERATOR_OUTPUT_PATH = (\"../data/final_answer_generated.json\")\n",
    "save_interval = 10 \n",
    "\n",
    "prompt_template = read_text_file(\"../prompts/final_answer_generator.txt\")\n",
    "inputs = load_json(\"../data/proposed_questions.json\")\n",
    "corpus_data = load_json(\"../data/proposed_questions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11672e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Future: 100%|██████████| 30/30 [00:00<00:00, 10714.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 9/30 outputs to ../data/final_answer_generated.json.\n",
      "Saving 19/30 outputs to ../data/final_answer_generated.json.\n",
      "Saving 29/30 outputs to ../data/final_answer_generated.json.\n",
      "Saving outputs to ../data/final_answer_generated.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run():\n",
    "    # what is corpusid_2_context\n",
    "    corpusid_2_context = {cur_dict['id']: cur_dict['context'] for cur_dict in corpus_data}\n",
    "\n",
    "    success_num, all_num = 0, 0\n",
    "    futures_to_data = {}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=FINAL_ANSWER_GENERATOR_NUM_WORKERS) as executor:\n",
    "            data_list = inputs[:FINAL_ANSWER_GENERATOR_MAX_GEN_TIMES] # Limit processing to first 100 items (FINAL_ANSWER_GENERATOR_MAX_GEN_TIMES)\n",
    "            for data_item in data_list: # Iterate through each data item in the limited list, here each item is a chunk (question)\n",
    "                if 'proposed-questions' not in data_item: # Skip items without proposed questions\n",
    "                    continue\n",
    "                proposed_questions = data_item['proposed-questions'] # extract proposed questions\n",
    "                chunk_id = data_item['id'] # extract document id\n",
    "                \n",
    "                # Build mapping structure: {clue_id: {doc_id: [sentence_id_list]}}\n",
    "                # This maps each objective fact (clue) to its document and sentence IDs\n",
    "                all_clueid2docid2senidlist = {}\n",
    "                objective_facts = data_item['objective-facts']\n",
    "                # Extract objective facts and their corresponding sentence ID strings\n",
    "                sens = data_item[\"sens\"] # e.g., [\"1, 2-4\", \"5\", \"6-8\"]\n",
    "\n",
    "                # Pair each fact with its sentence IDs, enumerate starting from 1 for fact_id\n",
    "                for (fact_id, objective_fact), sen in zip(enumerate(objective_facts, start=1), sens):\n",
    "                    sen_ids = re.findall(r'\\d+-\\d+|\\d+', sen) # Find all sentence ID patterns: ranges like \"1-3\" or singles like \"5\"\n",
    "                    sen_ids = expand_numbers_and_ranges(sen_ids) # Expand ranges into full integer lists: [\"1-3\", \"5\"] → [1, 2, 3, 5]\n",
    "                    all_clueid2docid2senidlist[fact_id] = {\n",
    "                        chunk_id: sen_ids # Store: fact_id (clue ID) → {chunk_id → [sentence IDs]}\n",
    "                    }\n",
    "\n",
    "                # Process each proposed question for this data item \n",
    "                # proposed_question_type is the key (e.g., \"question-1\")\n",
    "                # proposed_question_dict contains question data (question, answer, etc.)\n",
    "                for proposed_question_type, proposed_question_dict in proposed_questions.items():\n",
    "                    if \"positive\" in proposed_question_dict: # Skip if this question already has a 'positive' answer (already processed)\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract the original question text\n",
    "                    original_question = proposed_question_dict['question']\n",
    "                    positive_answer = proposed_question_dict['answer']\n",
    "                    if not positive_answer:\n",
    "                        continue\n",
    "                    \n",
    "                    # print(\"all_clueid2docid2senidlist:\", all_clueid2docid2senidlist)\n",
    "                    # print(\"positive_answer:\", positive_answer)\n",
    "\n",
    "                    # Convert [Clue xx] citations to [Doc xx, Sen yy] format\n",
    "                    # Uses all_clueid2docid2senidlist to map clue IDs to doc/sentence references\n",
    "                    positive_answer = replace_clue_with_doc_and_sen(all_clueid2docid2senidlist, positive_answer)\n",
    "\n",
    "                    needed_corpusid2corpus = {chunk_id: corpusid_2_context[chunk_id]}\n",
    "                    # Format as numbered XML-style string: \"0. <doc><doc-name>...</doc-name>...\"\n",
    "                    needed_corpusid2corpus_str = list_to_docided_string(needed_corpusid2corpus)\n",
    "                    \n",
    "                    cur_prompt = prompt_template.replace('[[QUESTION]]', original_question)\n",
    "                    cur_prompt = cur_prompt.replace('[[CONTEXT]]', needed_corpusid2corpus_str)\n",
    "                    cur_prompt = cur_prompt.replace('[[ANSWER]]', positive_answer)\n",
    "                    \n",
    "                    # Submit API call task to executor for async processing\n",
    "                    future = executor.submit(process_input_content, proposed_question_dict, cur_prompt)\n",
    "                    futures_to_data[future] = (\n",
    "                        None\n",
    "                    )\n",
    "\n",
    "                    # futures_to_data[future] = (\n",
    "                    #     proposed_question_dict.get('rephrased-questions', []),\n",
    "                    #     proposed_question_dict.get('rephrased-questions-part', []),\n",
    "                    #     proposed_question_dict.get('rephrased-questions-hybrid', [])\n",
    "                    # )\n",
    "\n",
    "                    # rephrased_question_type_list = ['rephrased-questions', 'rephrased-questions-part', 'rephrased-questions-hybrid']\n",
    "                    # for rephrased_question_type in rephrased_question_type_list:\n",
    "                    #     rephrased_questions = proposed_question_dict.get(rephrased_question_type, [])\n",
    "                    #     for rephrased_question_dict in rephrased_questions:\n",
    "                    #         # get answer with already replaced clues\n",
    "                    #         if 'reordered-question' in rephrased_question_dict:\n",
    "                    #             rephrased_question = rephrased_question_dict['reordered-question']\n",
    "                    #         else:\n",
    "                    #             rephrased_question = rephrased_question_dict['result']\n",
    "                    #         positive_answer = rephrased_question_dict['answer']\n",
    "                    #         positive_answer = replace_clue_with_doc_and_sen(all_clueid2docid2senidlist, positive_answer)\n",
    "                            \n",
    "                    #         cur_prompt = self.prompt_template.replace('[[QUESTION]]', rephrased_question)\n",
    "                    #         cur_prompt = cur_prompt.replace('[[CONTEXT]]', needed_corpusid2corpus_str)\n",
    "                    #         cur_prompt = cur_prompt.replace('[[ANSWER]]', positive_answer)\n",
    "                    #         future = executor.submit(self.process_input_content, rephrased_question_dict, self.CLIENT, cur_prompt)\n",
    "                    #         futures_to_data[future] = (\n",
    "                    #             proposed_question_dict.get('rephrased-questions', []),\n",
    "                    #             proposed_question_dict.get('rephrased-questions-part', []),\n",
    "                    #             proposed_question_dict.get('rephrased-questions-hybrid', [])\n",
    "                    #         )\n",
    "\n",
    "    \n",
    "    all_num = len(futures_to_data) # Calculate total number of tasks submitted\n",
    "    for future in tqdm(as_completed(futures_to_data), total=all_num, desc=\"Processing Future\", dynamic_ncols=True):\n",
    "        # rephrased_questions, rephrased_questions_part, rephrased_questions_hybrid = futures_to_data[future]\n",
    "        _ = futures_to_data[future] # Line 79: Retrieve the stored metadata (currently None, unused)\n",
    "        try:\n",
    "            # Get the result from the completed future\n",
    "            # Waits up to 10 minutes (600 seconds) for the result\n",
    "            # cur_response is the return value from process_input_content\n",
    "            # which is the updated proposed_question_dict with new fields:\n",
    "            #   - 'positive': short answer text\n",
    "            #   - 'corrected-answer': dict with 'short-answer' and 'long-answer'\n",
    "            cur_response = future.result(timeout=10*60)\n",
    "            if cur_response is None:\n",
    "                print(f\"Warning: Task returned None, may have failed\")\n",
    "                continue  # Don't count as success\n",
    "            \n",
    "            success_num += 1    \n",
    "            \n",
    "            # save (overwrite save)\n",
    "            if (success_num + 1) % save_interval == 0:\n",
    "                print(f'Progress: {success_num}/{all_num}')\n",
    "                save_json(inputs, FINAL_ANSWER_GENERATOR_OUTPUT_PATH)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print error message but continue processing other futures\n",
    "            # Note: Failed tasks are NOT counted in success_num\n",
    "            # Possible errors: timeout (>10 min), API failure, parsing errors\n",
    "            print(f\"Error processing future: {e}\")\n",
    "            \n",
    "    # Final save after all futures complete\n",
    "    # Condition: Save if ANY tasks succeeded OR output file doesn't exist yet\n",
    "    # This ensures data is always saved at the end, even if no interval saves occurred\n",
    "    if success_num or not os.path.exists(FINAL_ANSWER_GENERATOR_OUTPUT_PATH):\n",
    "        save_json(inputs, FINAL_ANSWER_GENERATOR_OUTPUT_PATH)\n",
    "    \n",
    "    return success_num, all_num\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragsynth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
