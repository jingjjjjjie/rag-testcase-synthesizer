{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e21992a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from tools.string_utils import read_text_file\n",
    "from tools.json_utils import load_json\n",
    "from tools.api import call_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f1d7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_execution_output_content(text):\n",
    "    \"\"\"\n",
    "    Extracts the structured content of \"Execution\" output dynamically for any question categories.\n",
    "    Args:\n",
    "        text (str): Input text containing \"Execution\" output.\n",
    "    Returns:\n",
    "        dict: A dictionary containing structured data for each dynamically matched question category.\n",
    "    \"\"\"\n",
    "    # Define regex to capture all question categories and their content\n",
    "    category_pattern = re.compile(r\"\\d+\\.\\s*<([^>]+-questions)>(.*?)((?=\\d+\\.\\s*<[^>]+-questions>)|$)\", re.S)\n",
    "\n",
    "    # Parse content for each category dynamically\n",
    "    categories = {}\n",
    "    for match in category_pattern.finditer(text):\n",
    "        category_name = match.group(1).strip()\n",
    "        category_content = match.group(2).strip()\n",
    "\n",
    "        # Function to parse individual questions within a category\n",
    "        def parse_questions(content):\n",
    "            question_pattern = re.compile(\n",
    "                r\"<question>(.*?)</question>\\s*<objective-facts>(.*?)</objective-facts>\\s*<reasoning>(.*?)</reasoning>\\s*<answer>(.*?)</answer>\",\n",
    "                re.S\n",
    "            )\n",
    "            ret = [\n",
    "                {\n",
    "                    \"question\": match.group(1).strip(),\n",
    "                    \"objective-facts\": match.group(2).strip(),\n",
    "                    \"reasoning\": match.group(3).strip(),\n",
    "                    \"answer\": match.group(4).strip()\n",
    "                }\n",
    "                for match in question_pattern.finditer(content)\n",
    "            ]\n",
    "            if len(ret) == 0:\n",
    "                return []\n",
    "            return ret\n",
    "\n",
    "        # Parse and store questions for the current category\n",
    "        ret = parse_questions(category_content)\n",
    "        if len(ret) == 0:\n",
    "            continue\n",
    "        categories[category_name] = ret[0]\n",
    "\n",
    "    return categories\n",
    "\n",
    "def process_input_content(cur_input, cur_propose_generator_prompt, i):\n",
    "        try:\n",
    "            propose_generator_response = call_api(cur_propose_generator_prompt, temperature=0.6)\n",
    "            proposed_questions = extract_execution_output_content(propose_generator_response)\n",
    "            result = {\n",
    "                **cur_input,\n",
    "                'proposed-questions': proposed_questions\n",
    "            }\n",
    "            return result, i\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing input {cur_input.get('id', 'unknown id')}: {e}\")\n",
    "            return None, None \n",
    "        \n",
    "def reformat_objective_facts(data):\n",
    "    result = {\"Objective Facts\": []}\n",
    "\n",
    "    # Reformat Objective Facts\n",
    "    for idx, fact in enumerate(data['objective-facts'], start=1):\n",
    "        result[\"Objective Facts\"].append(\n",
    "            f\"{idx}. <detailed-desc>{fact}</detailed-desc>\"\n",
    "        )\n",
    "    \n",
    "    result_str = \"\"\n",
    "    for key, values in result.items():\n",
    "        result_str += f\"{key}:\\n\" + \"\\n\".join(values) + \"\\n\"\n",
    "    \n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc74d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 items from ../data/fact_extracted.json\n"
     ]
    }
   ],
   "source": [
    "inputs = load_json(\"../data/fact_extracted.json\")\n",
    "propose_generator_prompt = read_text_file(\"../prompts/propose_generator_content.txt\")\n",
    "\n",
    "PROPOSE_GENERATOR_NUM_WORKERS = 4\n",
    "PROPOSE_GENERATOR_MAX_GEN_TIMES = 100\n",
    "PROPOSE_GENERATOR_OUTPUT_PATH = '../data/proposed_questions.json'\n",
    "save_interval = 10\n",
    "\n",
    "\n",
    "def run():\n",
    "    tasks = []\n",
    "    success_num, all_num = 0, 0\n",
    "    \n",
    "    # create a pool of threads (parallel worker)\n",
    "    with ThreadPoolExecutor(max_workers=PROPOSE_GENERATOR_NUM_WORKERS) as executor: \n",
    "        for i, cur_input in enumerate(inputs[:PROPOSE_GENERATOR_MAX_GEN_TIMES]): # only process questions (input) up to n\n",
    "                if 'proposed-questions' in cur_input: # check if proposed questions already exist\n",
    "                    continue #  skip inputs that contain 'proposed questions' key\n",
    "                \n",
    "                context = reformat_objective_facts(cur_input) \n",
    "                cur_propose_generator_prompt = propose_generator_prompt.replace('[[CONTEXT]]', context)\n",
    "                #  Submit a background task to the thread pool\n",
    "                future = executor.submit(process_input_content, cur_input, cur_propose_generator_prompt, i) # the original input, the prompt(with context inserted) index\n",
    "                tasks.append(future) # stores each future so we can later wait for results\n",
    "\n",
    "        all_num = len(tasks)\n",
    "        # wait for tasks to finish \n",
    "        for future in tqdm(as_completed(tasks), total=len(tasks), desc=\"Generating\", dynamic_ncols=True):\n",
    "            try:\n",
    "                result, i = future.result(timeout=10*60) # retrieves the result from the finished task, waits up to 10 minutes for each task\n",
    "                inputs[i] = result # writes the result back into the original input list\n",
    "                \n",
    "                success_num += 1\n",
    "                if success_num % save_interval == 0: # saves every \"save_interval\" successful inputs\n",
    "                    dir_path = os.path.dirname(PROPOSE_GENERATOR_OUTPUT_PATH) # create output dir if needed\n",
    "                    os.makedirs(dir_path, exist_ok=True)\n",
    "                    print(f'Saving {success_num}/{all_num} outputs to {PROPOSE_GENERATOR_OUTPUT_PATH}.')\n",
    "                    with open(PROPOSE_GENERATOR_OUTPUT_PATH, 'w', encoding=\"utf-8\") as f:\n",
    "                        json.dump(inputs, f, indent=2, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing input id {cur_input['id']}: {e}\")\n",
    "    if success_num or not os.path.exists(PROPOSE_GENERATOR_OUTPUT_PATH):\n",
    "        dir_path = os.path.dirname(PROPOSE_GENERATOR_OUTPUT_PATH)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f'Saving {success_num}/{all_num} outputs to {PROPOSE_GENERATOR_OUTPUT_PATH}.')\n",
    "        with open(PROPOSE_GENERATOR_OUTPUT_PATH, 'w', encoding=\"utf-8\") as f:\n",
    "            json.dump(inputs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return success_num, all_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52fe362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 10/10 [00:28<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 10/10 outputs to ../data/proposed_questions.json.\n",
      "Saving 10/10 outputs to ../data/proposed_questions.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "success_num, all_num = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c451d777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_num, all_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragsynth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
